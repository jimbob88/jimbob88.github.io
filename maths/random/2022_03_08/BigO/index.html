<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big O Notation</title>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/default.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
        </script>
    <script type="text/javascript" charset="UTF-8"
        src="https://cdn.jsdelivr.net/npm/jsxgraph/distrib/jsxgraphcore.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/jsxgraph/distrib/jsxgraph.css" />
</head>

<body>
    <h1>Big O Notation</h1>
    <p>
        Big O notation is probably something you have come across if you have ever done programming or looked at
        mathematical algorithms. Many algorithms (i.e. Ramujan's Formula) list a Big O notation, examples of these
        notations are:
        $$
        \Large
        \begin{multline}
        \\
        O(1) \\
        O(n) \\
        O(n^2) \\
        O(n \log(n)) \\ \\
        \end{multline}
        $$
        But what do these things <i>actually</i> mean?
    </p>
    <h3>
        A measure of speed
    </h3>
    <p>
        Generally speaking, Big O notation can be treated as the "speed" of the algorithm. But this term isn't entirely
        correct, it should instead be seen as "how much an increase in difficulty, increase time".
    </p>
    <h2>Programming Examples</h2>
    <p>
        Now that statement might not instantly make sense, but stick with me here, using these coding examples, I hope
        to help you understand.
    </p>
    <h3>\(O(1)\) Complexity</h3>
    <pre>
    <code class="language-python">
def get_item(l, n):
    return l[n]

x = [0, 1, 2, 3]
get_item(x, 2)
    </code>
    
</pre>
    <p>
        We call the algorithm <i>get_item</i> difficulty: \( O(1) \). This is because, even if the list is 10000s of
        items long, the difficulty of accessing the "nth" term is no more complicated. I.e. finding item 1 and finding
        item 10000 are equally as difficult.
    </p>
    <h3>\(O(n)\) Complexity</h3>
    <p>
        Now let us take a slightly different problem, what if I asked you to (non-pythonically) find an item in a list
        that's equal to 1.
    </p>
    <pre>
        <code class="language-python">
x = [0, 1, 2, 3]
for item in x:
    if item == 1:
        break
        </code>
    </pre>
    <p>
        We say this \(\text{has a worse case scenario of } O(n)\). But what does "worst case scenario" mean?
    </p>
    <p>
        We say it has a worst case scenario, because the worst case scenario is that the list looks like this:
    </p>
    <code class="language-python">
        x = [..., 1]
    </code>
    <p>
        When the final item of the list is 1, the computer has to look through the whole list to find this item.
        <br />
        In a best case scenario, this problem has Complexity: \(O(1)\)
    </p>
    <code>
        x = [1 ....]
    </code>
    <p>
        When the algorithm finds the first value as the value "1", its best case is only needing to do one function.
        This is no different to our first example of <i>get_item</i>.
    </p>
    <h3>\(O(n^2)\) Complexity</h3>
    <p>
        Let's take an example of a 2-dimensional (square) list of values, and try and do the same as before, where we
        try and find the value that's equal to 1.
    </p>
    <pre>
        <code class="language-python">
x = [
    [4, 3, 7, 3],
    [9, 4, 3, 2],
    [2, 1, 3, 5],
    [6, 7, 1, 5]
]
for row in x:
    for cell in row:
        if cell == 1:
            exit()
        </code>
    </pre>
    <p>
        So, as you can see, we now have two for-loops inside each other, this means that it has to go through every
        single row, and then also go through each column of those rows (cell).
        <br />
        This problem has a worst case scenario of \(O(n^2)\) complexity, because if the value of 1 were in the far right
        corner of this table, it would have to iterate over every single item in the list to reach there.
    </p>

    <h2>Big O notation in mathematics</h2>
    <p>
        We can find the complexity of a problem by simply looking at the formula that requires it. For example, let's
        look at the following formula:
    </p>
    <p>
        $$
        y = x^2 + 2x + 1
        $$
    </p>
    <p>
        As the value of \(x\) increases, the value of the \(x^2\) increases much more than the value of \(2x\). And the
        value of \(1\) will remain the same.
        <br />
        In order to understand this better, let's plot it on a graph:
    </p>
    <div id="box1" class="jxgbox" style="width:400px; height:400px;"></div>
    <script type="text/javascript">
        var board = JXG.JSXGraph.initBoard('box1', { boundingbox: [-1, 10, 10, -1], axis: true, grid: true });
        var graph_quadratic = board.create('functiongraph',
            [function (x) { return x ** 2; }, -50, 50]
        );
        var graph_linear = board.create('functiongraph',
            [function (x) { return 2 * x; }, -50, 50], { strokeColor: 'red' }
        );
        var graph_line = board.create('functiongraph',
            [function (x) { return 1; }, -50, 50], { strokeColor: 'green' }
        );
    </script>
    <p>
        If you can't see this graph, try plotting this on a bit of paper, trust me, it'll help.
    </p>
    <p>
        As we zoom-out on this graph, we can see that the \(y = x^2\) graph (blue) gets bigger much quicker than the \(y
        = 2x\) (red) graph. For this equation, we call its difficult just \(O(n^2)\) because as the value of x increases
        it approaches infinity.
    </p>
    <p>
        If you want to read up more about this, I'd thoroughly recommend looking at <a
            href="https://www.math.ucdavis.edu/~kouba/CalcOneDIRECTORY/liminfsol1directory/LimInfSol1.html">fractional
            limits of
            infinity</a>.
    </p>

    <h2>
        A look at estimating the performance of an algorithm
    </h2>

    <p>
        This section of the guide is inspired by A-Level questions, even if you aren't taking A-level, it is still
        hopefully interesting!
    </p>
    <p>
        Example problem:
    </p>
    <p>
        $$
        \begin{gather}
        \text{A list of length 100, takes 5s to be sorted using Bubble Sort.} \\
        \text{Given that Bubble Sort is of complexity } O(n^2) \\
        \text{Calculate the time take for a list of length 500}
        \end{gather}
        $$
    </p>
    <p>
        First we need to look at the multiplier increase in size. To do this do: \(\frac{500}{100}\). This should give a
        \(5\) times increase. Because the problem has a difficulty of \(O(n^2)\), we will assume it's the worst case,
        and square this \(5\). \(5^2 = 25\). Then times this by the original time taken: \(25 \times 5 = 125\).
    </p>
    <p>
        This gives an overall formula of (for \(O(n^2)\)): <br />
        $$
        \text{new time taken} = \left (\frac{\text{new length}}{\text{old length}} \right )^2 \times
        \text{old time taken}
        $$
    </p>

    <p>
        What if it were for a difficulty of \(O(n!)\) (something we haven't looked at yet)?
    </p>
    <p>
        $$
        \text{new time taken} = \left (\frac{\text{new length}}{\text{old length}} \right )! \times
        \text{old time taken}
        $$
    </p>


    <h2>
        A quick dive into the limits of functions
    </h2>
    <p>
        Let's take an example formula as a reference point:
    </p>
    <p>
        $$
        \Large
        f(x) = \frac{x}{x^2-100},
        x \neq -10, 10
        $$
    </p>
    <p>
        REMEMBER: \(x\) cannot equal to \(10, -10\) because that would make a division by 0.
    </p>
    <p>
        Now let's say, we start increasing the value of \(x\) all the way up to \(\inf\). In mathematics we write this
        as:
    </p>
    <p>
        $$\Large\begin{gather}
        \lim_{x \to +\infty} f(x)
        \\
        \text{or}
        \\
        \lim_{x \to \infty} f(x)
        \end{gather}$$
    </p>
    <p>
        So let's rewrite our formula, using this standard:
    </p>
    <p>
        $$\Large\begin{gather}
        \lim_{x \to \infty} f(x) = \frac{x}{x^2-100} \\
        x \neq -10, 10
        \end{gather}$$
    </p>
    <p>
        Let's now plot this function, to give an idea of what it looks like!
    </p>
    <div id="box2" class="jxgbox" style="width:400px; height:400px;"></div>
    <script type="text/javascript">
        var board = JXG.JSXGraph.initBoard('box2', { boundingbox: [-1, 50, 20, -50], axis: true, grid: true });
        var graph_quadratic = board.create('functiongraph',
            [function (x) { return x / ((x ** 2) - 100); }, -50, 50]
        );
    </script>
    <p>
        Can you see, as it gets closer to infinity (as the value increases) it starts getting closer and closer to the
        x-axis! <br />
        This means the \(y\) value (\(f(x)\) value) is approaching 0. We can write this as:
    </p>
    <p>
        $$\Large\begin{gather}
        \lim_{x \to \infty} f(x) = \frac{x}{x^2-100} = 0 \\
        x \neq -10, 10
        \end{gather}$$
    </p>
</body>

</html>